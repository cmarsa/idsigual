{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 __Statistical Inference__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not only one way to address the problem of statistical inference. In fact,\n",
    "there are two main approaches to statistical inference: the frequentist\n",
    "and Bayesian approaches, Their diiferences are sublte but fundamental:\n",
    "\n",
    " + In the case of _frequentist apprach_, the main assumption is that there is\n",
    "   a population, which can be represented by several parameters, from which\n",
    "   we can obtain numerous random samples. The only way to derive the information\n",
    "   aboyt these parameters is to take a sample of the population, to compute\n",
    "   the parameters of the sample an to use statistical inference techqiniques to\n",
    "   make probable propositions regarding population parameters.\n",
    "   \n",
    " + The _Bayesian apprach_ is based on a considereation that data are fixed, not \n",
    "   the result of a repeatable sampling process, but parameters describing data\n",
    "   can be described proabilisitically. To this end, Bayersian inference methods focus\n",
    "   on reproducing parameter distributions that represent all the knowledge we \n",
    "   can extract from the sample and from prioir information about the problem.\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assumptions are related in the first case to a sampling process; and to a statistical\n",
    "model in the second case. Correct inference requires these assumptions to be correct.\n",
    "The fulfillment of this requirement is not part of the method, but it is the responsibility\n",
    "of the data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Frequentist Approach to Statistical Inference__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we adopt the frequentist approach, is to produce probable\n",
    "propositions concerning population param-\n",
    "eters from analysis of a sample. The most important classes of propositions are as\n",
    "follows:\n",
    "\n",
    " + Propositions about _point estimates_. Apoint estimate is a particular value that\n",
    "   best approximates some parameter of interest. For example, the mean or the\n",
    "   variance of a sample.\n",
    "   \n",
    " + Propositions about _confidence intervals_ or _set estimates_. A confidence interval\n",
    "   is a range of values that best represents some parameter of interest.\n",
    "   Propositions about the acceptance or rejection of a _hypothesis_.\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all these cases, the production of propositions is based on a simple assumptions:\n",
    "we can estimate the probability that the result represented by the proposition\n",
    "has been caused by chance. The estimation of this probability by sound method is one\n",
    "of the main topics of statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Measuring the Variability in Estimates__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimates produced by descriptive statistics are not equal to the truth but they are\n",
    "better as more data become available. So, it makes sense to use them as central\n",
    "elements of our propositions and to measure its variability with respect to the sample\n",
    "size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Point Estimates__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us suppose that we are interested in describing the daily number of\n",
    "traffic accidents in the streets of Barcelona in 2013. If we have access to the population, the\n",
    "computation of this parameter is a simple operation: the total number of accidents\n",
    "divided by 365."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\n",
    "    'input/accidents_gu_bnc_2013.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N�mero d'expedient</th>\n",
       "      <th>Codi districte</th>\n",
       "      <th>Nom districte</th>\n",
       "      <th>NK barri</th>\n",
       "      <th>Nom barri</th>\n",
       "      <th>Codi carrer</th>\n",
       "      <th>Nom carrer</th>\n",
       "      <th>Num postal caption</th>\n",
       "      <th>Descripci� dia setmana</th>\n",
       "      <th>Dia de setmana</th>\n",
       "      <th>...</th>\n",
       "      <th>Hora de dia</th>\n",
       "      <th>Descripci� torn</th>\n",
       "      <th>Descripci� causa vianant</th>\n",
       "      <th>N�mero de morts</th>\n",
       "      <th>N�mero de lesionats lleus</th>\n",
       "      <th>N�mero de lesionats greus</th>\n",
       "      <th>N�mero de v�ctimes</th>\n",
       "      <th>N�mero de vehicles implicats</th>\n",
       "      <th>Coordenada UTM (Y)</th>\n",
       "      <th>Coordenada UTM (X)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013S007360</td>\n",
       "      <td>-1</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>-1--1--1</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>-1</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>Dimecres</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>Tarda</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013S007723</td>\n",
       "      <td>10</td>\n",
       "      <td>Sant Mart�</td>\n",
       "      <td>101-10-64</td>\n",
       "      <td>el Camp de l'Arpa del Clot</td>\n",
       "      <td>152600</td>\n",
       "      <td>Guinard�</td>\n",
       "      <td>0028 0032</td>\n",
       "      <td>Dimarts</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>Tarda</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4585218,67</td>\n",
       "      <td>431621,41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013S005373</td>\n",
       "      <td>10</td>\n",
       "      <td>Sant Mart�</td>\n",
       "      <td>101-10-64</td>\n",
       "      <td>el Camp de l'Arpa del Clot</td>\n",
       "      <td>134801</td>\n",
       "      <td>Freser</td>\n",
       "      <td>0053 0053</td>\n",
       "      <td>Dimarts</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>Mat�</td>\n",
       "      <td>Creuar per fora pas de vianants</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4585049,89</td>\n",
       "      <td>431605,09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013S001486</td>\n",
       "      <td>10</td>\n",
       "      <td>Sant Mart�</td>\n",
       "      <td>101-10-64</td>\n",
       "      <td>el Camp de l'Arpa del Clot</td>\n",
       "      <td>161407</td>\n",
       "      <td>Ind�stria</td>\n",
       "      <td>0224 0224</td>\n",
       "      <td>Dimarts</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>Mat�</td>\n",
       "      <td>Altres</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4584836,20</td>\n",
       "      <td>431302,26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013S008254</td>\n",
       "      <td>10</td>\n",
       "      <td>Sant Mart�</td>\n",
       "      <td>101-10-64</td>\n",
       "      <td>el Camp de l'Arpa del Clot</td>\n",
       "      <td>161101</td>\n",
       "      <td>Independ�ncia</td>\n",
       "      <td>0357 0357</td>\n",
       "      <td>Dilluns</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>Tarda</td>\n",
       "      <td>Desconegut</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4584704,26</td>\n",
       "      <td>431385,76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  N�mero d'expedient  Codi districte Nom districte   NK barri  \\\n",
       "0        2013S007360              -1    Desconegut   -1--1--1   \n",
       "1        2013S007723              10    Sant Mart�  101-10-64   \n",
       "2        2013S005373              10    Sant Mart�  101-10-64   \n",
       "3        2013S001486              10    Sant Mart�  101-10-64   \n",
       "4        2013S008254              10    Sant Mart�  101-10-64   \n",
       "\n",
       "                    Nom barri  Codi carrer     Nom carrer Num postal caption  \\\n",
       "0                  Desconegut           -1     Desconegut         Desconegut   \n",
       "1  el Camp de l'Arpa del Clot       152600       Guinard�          0028 0032   \n",
       "2  el Camp de l'Arpa del Clot       134801         Freser          0053 0053   \n",
       "3  el Camp de l'Arpa del Clot       161407      Ind�stria          0224 0224   \n",
       "4  el Camp de l'Arpa del Clot       161101  Independ�ncia          0357 0357   \n",
       "\n",
       "  Descripci� dia setmana  Dia de setmana  ... Hora de dia  Descripci� torn  \\\n",
       "0               Dimecres               3  ...          21            Tarda   \n",
       "1                Dimarts               2  ...          21            Tarda   \n",
       "2                Dimarts               2  ...          10             Mat�   \n",
       "3                Dimarts               2  ...          10             Mat�   \n",
       "4                Dilluns               1  ...          16            Tarda   \n",
       "\n",
       "          Descripci� causa vianant N�mero de morts  N�mero de lesionats lleus  \\\n",
       "0                       Desconegut               0                          1   \n",
       "1                       Desconegut               0                          1   \n",
       "2  Creuar per fora pas de vianants               0                          1   \n",
       "3                           Altres               0                          1   \n",
       "4                       Desconegut               0                          1   \n",
       "\n",
       "   N�mero de lesionats greus N�mero de v�ctimes N�mero de vehicles implicats  \\\n",
       "0                          0                  1                            2   \n",
       "1                          0                  1                            2   \n",
       "2                          0                  1                            1   \n",
       "3                          0                  1                            1   \n",
       "4                          0                  1                            2   \n",
       "\n",
       "   Coordenada UTM (Y)  Coordenada UTM (X)  \n",
       "0                  -1                  -1  \n",
       "1          4585218,67           431621,41  \n",
       "2          4585049,89           431605,09  \n",
       "3          4584836,20           431302,26  \n",
       "4          4584704,26           431385,76  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['N�mero d'expedient', 'Codi districte', 'Nom districte', 'NK barri',\n",
       "       'Nom barri', 'Codi carrer', 'Nom carrer', 'Num postal caption',\n",
       "       'Descripci� dia setmana', 'Dia de setmana', 'Descripci� tipus dia',\n",
       "       'NK Any', 'Mes de any', 'Nom mes', 'Dia de mes', 'Hora de dia',\n",
       "       'Descripci� torn', 'Descripci� causa vianant', 'N�mero de morts',\n",
       "       'N�mero de lesionats lleus', 'N�mero de lesionats greus',\n",
       "       'N�mero de v�ctimes', 'N�mero de vehicles implicats',\n",
       "       'Coordenada UTM (Y)', 'Coordenada UTM (X)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def strip_accents(text:str) -> str:\n",
    "    \"\"\"\n",
    "    Strip accents from input String.\n",
    "    \n",
    "    arguments\n",
    "    ---------\n",
    "        text: text to be parsed\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "        text: parsed text with accents removed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except (TypeError, NameError): # unicode is a default on python 3 \n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = text.encode('ascii', 'ignore')\n",
    "    text = text.decode(\"utf-8\")\n",
    "    return str(text)\n",
    "\n",
    "\n",
    "\n",
    "def parse_col_names(colnames_list: list) -> dict:\n",
    "    \"\"\"\n",
    "    Parses the column names to a standard format:\n",
    "    removes parentheses, slashes and $,\n",
    "    converts every character to lower case, and converts\n",
    "    blank spaces to `_`.\n",
    "    arguments\n",
    "    ---------\n",
    "        colnames_list: a list-like structure that haves\n",
    "            the current names of the columns to be parsed.\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "        new_col_names: a dictionary containing the old column names\n",
    "            and their respective parsed names.\n",
    "    \"\"\"\n",
    "    new_col_names = {key: 0 for key in colnames_list}\n",
    "    for key, value in new_col_names.items():\n",
    "        text = strip_accents(key.lower())\n",
    "        text = re.sub(' - ', '_', text)\n",
    "        text = re.sub('/[ ]+', '_', text)\n",
    "        text = re.sub('[ ]-+', '_', text)\n",
    "        text = re.sub('[. ]+', '_', text)\n",
    "        text = re.sub('[ ]+', '_', text)\n",
    "        text = re.sub('[-]+', '_', text)\n",
    "        text = re.sub('[^0-9a-zA-Z_-]', '', text)\n",
    "\n",
    "        # assign to dict key the new_col_name\n",
    "        new_col_names[key] = text\n",
    "        \n",
    "    # remove the _ left at the start and/or end of the string\n",
    "    for key, value in new_col_names.items():\n",
    "        text = re.sub('^_*|_*$', '', value)\n",
    "        new_col_names[key] = text\n",
    "        \n",
    "    return new_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns = parse_col_names(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = data['dia_de_mes'].apply(lambda x: str(x)) + '-' + \\\n",
    "               data['mes_de_any'].apply(lambda x: str(x)) + '-'+ '2013'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       16-10-2013\n",
       "1       29-10-2013\n",
       "2        23-7-2013\n",
       "3        26-2-2013\n",
       "4       18-11-2013\n",
       "           ...    \n",
       "9452    10-11-2013\n",
       "9453      5-9-2013\n",
       "9454     14-8-2013\n",
       "9455     20-2-2013\n",
       "9456     23-9-2013\n",
       "Name: date, Length: 9457, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['date'])\n",
    "accidents = data.groupby(['date']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.90958904109589\n"
     ]
    }
   ],
   "source": [
    "print(accidents.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now, for illustrative purposes, let us suppose that we only have access to a\n",
    "limited part of the data (the sample): the number of accidents during some days of\n",
    "2013. Can we still give an approximation of the population mean?\n",
    "The most intuitive way to go about providing such a mean is simply to take the\n",
    "sample mean. The sample mean is a point estimate of the population mean. If we can\n",
    "only choose one value to estimate the population mean, then this is our best guess.\n",
    "\n",
    "The problem we face is that estimates generally vary from one sample to another,\n",
    "and this sampling variation suggests our estimate may be close, but it will not be\n",
    "exactly equal to our parameter of interest. How can we measure this variability?\n",
    "\n",
    "In our example, because we have access to the population, we can empirically build\n",
    "the sampling distribution of the sample mean for a given number of observations.\n",
    "Then, we can use the sampling distribution to compute a measure of the variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999 / 10000\r"
     ]
    }
   ],
   "source": [
    "# making an empirical sample distribution of the mean\n",
    "# s = 100000, n = 200\n",
    "\n",
    "# population\n",
    "accs = accidents.to_frame()\n",
    "s = 10000; n = 200; means = []\n",
    "\n",
    "# sample generation\n",
    "for i in range(0, s):\n",
    "    print(f'{i:03d} / {s:03d}', end = '\\r')\n",
    "    rows = np.random.choice(accs.index.values, n)\n",
    "    sample = accidents.loc[rows]\n",
    "    means.append(sample.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pd.Series(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "means.plot.hist(bins = 30, edgecolor = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, given a point estimate from a sample of size n, we define its sampling\n",
    "distribution as the distribution of the point estimate based on samples of size n\n",
    "from its population. This definition is valid for point estimates of other population\n",
    "parameters, such as the population median or population standard deviation, but we\n",
    "will focus on the analysis of the sample mean.\n",
    "\n",
    "The sampling distribution of an estimate plays an important role in understanding\n",
    "the real meaning of propositions concerning point estimates. It is very useful to think\n",
    "of a particular point estimate as being drawn from such a distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __The traditional approach__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real problems, we do not have access to the real population and so estimation\n",
    "of the sampling distribution of the estimate from the empirical distribution of the\n",
    "sample replications is not an option. But this problem can be solved by making use\n",
    "of some theoretical results from traditional statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can be mathematically shown that given _n_ independent observations\n",
    "$\\{x_i\\}_i = 1, 2, ...,n$ of a population with a standard deviation\n",
    "$\\sigma_x$, the standard deviation of the sample mean $\\sigma_\\bar{x}$,\n",
    "or _standard error_, can be approximated by:\n",
    "\n",
    "$$ SE = \\frac{\\sigma_x}{\\sqrt{n}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This formula uses the standard deviation of the population $\\sigma_x$ , which is not known,\n",
    "but it can be shown that if it is substituted by its empirical estimate $\\hat{\\sigma}_x $  , the estimation\n",
    "is sufficiently good if n > 30 and the population distribution is not skewed. This\n",
    "allows us to estimate the standard error of the sample mean even if we do not have\n",
    "access to the population.\n",
    "So, how can we give a measure of the variability of the sample mean? The answer\n",
    "is simple: by giving the empirical standard error of the mean distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "rows = np.random.choice(accs.index.values, 200)\n",
    "sample = accs.loc[rows]\n",
    "est_sigma_mean = sample.std() / math.sqrt(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direct estimation of SE from one sample of 200 elements:  0.675709193790394\n",
      "estimation of the SE by simulating 1000 samples of 200 elements:  0.6449065013626006\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'direct estimation of SE from one sample of 200 elements: ', est_sigma_mean.mean()\n",
    ")\n",
    "\n",
    "print(\n",
    "    'estimation of the SE by simulating 1000 samples of 200 elements: ', np.array(means).std()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the case of the sample mean, there is no formula for the standard error of\n",
    "other interesting sample estimates, such as the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the case of the sample mean, there is no formula for the standard error of\n",
    "other interesting sample estimates, such as the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Computationally Intensive Approach__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider from now that our full dataset is a sample from a hypothetical\n",
    "population (this is the most common situation when analyzing real data!).\n",
    "A modern alternative to the traditional approach to statistical inference is the\n",
    "_bootstrapping_ method. In the bootstrap, we draw _n_ observations with replacement\n",
    "from the original data to create a bootstrap sample or resample. Then, we can calculate\n",
    "the mean for this resample. By repeating this process a large number of times, we\n",
    "can build a good approximation of the mean sampling distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bstrp:  9999 / 10000| mean(sample): 26.6137\r"
     ]
    }
   ],
   "source": [
    "def mean_bootstrap(X, numberb):\n",
    "    x = [0] * numberb\n",
    "    for i in range(0, numberb):\n",
    "        sample = [\n",
    "            X[j] for j in np.random.randint(len(X), size = len(X))\n",
    "        ]\n",
    "        x[i] = np.mean(sample)\n",
    "        print(\n",
    "            f'bstrp: {i:5d} / {numberb:5d}| mean(sample): {np.mean(sample):4.4f}', end = '\\r'\n",
    "        )\n",
    "    return x\n",
    "\n",
    "m = mean_bootstrap(accidents, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_series = pd.Series(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean estimate:  25.910511780821917\n"
     ]
    }
   ],
   "source": [
    "print('mean estimate: ', np.mean(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_series.hist(bins = 30, edgecolor = 'k')\n",
    "plt.axvline(m_series.mean(), color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of the bootstrapping method is that the observed sample contains\n",
    "sufficient information about the underlying distribution. So, the information we can\n",
    "extract from resampling the sample is a good approximation of what can be expected\n",
    "from resampling the population.\n",
    "The bootstrapping method can be applied to other simple estimates such as the\n",
    "median or the variance and also to more complex operations such as estimates of\n",
    "censored data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Confidence Intervals__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A point estimate $\\Theta$, such as the sample mean, provides a _single plausible value for a parameter_.\n",
    "However, as we have seen, a point estimate is rarely perfect; usually there is some error in the estimate.\n",
    "That is why we have suggested using the standard error as a measure of its variability.\n",
    "\n",
    "Instead of that, a next logical step would be to provide a plausible range of values for the parameter.\n",
    "A plausible range of values for the sample parameter is called a _confidence interval_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will base the definition of _confidence interval_ on two ideas:\n",
    "1. Our point estimate is the most plausible value of the parameter, so it makes sense\n",
    "   to build the confidence interval around the point estimate.\n",
    "2. The _plausibility_ of a range of values can be defined from the sampling\n",
    "   distribution of the estimate.\n",
    "   \n",
    "For the case of the mean, the Central Limit Theorem states that its sampling distribution is normal:\n",
    "\n",
    "__Theorem 4.1__ _Given a population with a finite mean $\\mu$ and a finite non-zero variance\n",
    "$\\sigma^2$, the sampling distribution of the mean approaches a normal distribution with a \n",
    "mean of $\\mu$ and a variance of $\\sigma^2 / n $ as n, the sample size, increases._\n",
    "\n",
    "In this case, and in order to define an interval, we can make use of a well-known\n",
    "result from probability that applies to normal distributions: roughly 95%\n",
    "of the time our estimate will be within 1.96 standard errors of the true mean of the distribution.\n",
    "\n",
    "If the interval spreads out 1.96 standard errors from a normally distributed point\n",
    "estimate, intuitively we can say that we are roughly 95% confident that we have\n",
    "captured the true parameter.\n",
    "\n",
    "$$ CI = [\\Theta - 1.96 \\times SE, \\Theta + 1.96 \\times SE]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = accidents.mean()\n",
    "se = accidents.std() / math.sqrt(len(accidents))\n",
    "ci = [m - se * 1.96, m + se * 1.96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence intervak:  [24.975156065800284, 26.8440220163915]\n"
     ]
    }
   ],
   "source": [
    "print('confidence intervak: ', ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to consider confidence intervals where the confidence level is somewhat\n",
    "higher than 95%: perhaps we would like a confidence level of 99%. To create a 99% confidence\n",
    "interval, change 1.96 in the 95% confidence interval formula to be 2.58 (it can be shown\n",
    "that 99% of the time a normal random varialbe will be within 2.58 standard deviations of the mean.\n",
    "\n",
    "In general, if the point estimate follows the normal model with standard error $SE$, then a \n",
    "confidence interval for the population parameter is \n",
    "\n",
    "$$ \\Theta \\pm z \\times SE $$\n",
    "\n",
    "Where $z$ corresponds to the confindence level selected:\n",
    " - z = 1.65, confidence = 90%\n",
    " - z = 1.96, confidence = 95%\n",
    " - z = 2.58, confidence = 99%\n",
    " - z = 3.291, confidence = 99.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean estimate:  25.90982an(sample): 26.3945\n",
      "SE of the estimate:  0.471426105600784\n",
      "confidence interval:  [24.986301369863014, 26.84109589041096]\n"
     ]
    }
   ],
   "source": [
    "# compute a 95% confidence interval of the sample mean\n",
    "# using bootstrapping\n",
    "m = mean_bootstrap(accidents, 10000)\n",
    "sample_mean = np.mean(m)\n",
    "sample_se = np.std(m)\n",
    "\n",
    "print('mean estimate: ', sample_mean)\n",
    "print('SE of the estimate: ', sample_se)\n",
    "\n",
    "ci = [np.percentile(m, 2.5), np.percentile(m, 97.5)]\n",
    "print('confidence interval: ', ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does 95% confident Mean?\n",
    "The real meaning of “confidence” is not evident and it must be understood from the\n",
    "point of view of the generating process.\n",
    "Suppose we took many (infinite) samples from a population and built a 95%\n",
    "confidence interval from each sample. Then about 95% of those intervals would\n",
    "contain the actual parameter. If this simulation could be done with infinite different samples,\n",
    "5% of those intervals would not contain the true mean.\n",
    "So, when faced with a sample, the correct interpretation of a confidence interval\n",
    "is as follows:\n",
    "\n",
    "__In 95% of the cases, when I compute the 95% confidence interval from this sample,\n",
    "the true mean of the population will fall within the invetrval defined by these bounds.__\n",
    "\n",
    "__We cannot say either that out specific smaple contains the true parameter or\n",
    "that the interval has a 95% chance of containing the true patameter.\n",
    "That interpretration would not be correct under the assumptions of traditional\n",
    "statistics.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Hypothesis Testing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giving a measure of the variability of our estimates is one way of producing a\n",
    "statistical proposition about the population, but not the only one. R.A. Fisher (1890–\n",
    "1962) proposed an alternative, known as __hypothesis testing__, that is based on the\n",
    "concept of __statistical significance__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us suppose that a deeper analysis of traffic accidents in Barcelona results in a\n",
    "difference between 2010 and 2013. Of course, the difference could be caused only\n",
    "by chance, because of the variability of both estimates. But it could also be the case\n",
    "that traffic conditions were very different in Barcelona during the two periods and,\n",
    "because of that, data from the two periods can be considered as belonging to two\n",
    "different populations. Then, the relevant question is: Are the observed effects real or\n",
    "not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, the question is usually translated to: _Were the obserbed effectes statistically significant?_\n",
    "The process of determining the statistical significance of an effect is called _hypothesis testing._\n",
    "\n",
    "This process starts by simplifying the options into two competing hypotheses:\n",
    " + $H_0$: The mean number of daily traffic accidents is the same in 2010 and 2013\n",
    "   (there is only one population, one true mean, and 2010 and 2013 are just different\n",
    "   samples from the same population)\n",
    " + $H_A$: The mean number of daily traffic accidents in 2010 and 2013 is different\n",
    "   (2010 and 2013 are two samples from two different populations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call $H_0$ the _null hypothesis_ and it represents a _skepticap_ point of view:\n",
    "the effect we have observed is due to chance (due to specific sample bias).\n",
    "$H_A$ is the _alternative hypothesis_ and it represents tthe oter point of view:\n",
    "the effect is real.\n",
    "\n",
    "The general rule of frequentist hypothesis testing: we will not _discard_ $H_0$\n",
    "(and hence we will not consider $H_A$) unless the observed effect\n",
    "is _implausible_ under $H_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010: Mean 24.81095890410959\n",
      "2013: Mean 25.90958904109589\n"
     ]
    }
   ],
   "source": [
    "# testing hypothesis using confidence intervals\n",
    "# to measure the plausibility of hypothesis\n",
    "accidents_2010 = pd.read_csv('input/ACCIDENTS_GU_BCN_2010.csv', encoding = 'latin-1')\n",
    "accidents_2010 = accidents_2010.rename(columns = parse_col_names(accidents_2010.columns))\n",
    "\n",
    "# create a new column which is the date\n",
    "accidents_2010['date'] = accidents_2010['dia_de_mes'].apply(lambda x: str(x)) + \\\n",
    "                         '-' + accidents_2010['mes_de_any'].apply(lambda x: str(x))\n",
    "\n",
    "dates_2010 = accidents_2010['date']\n",
    "counts_2010 = accidents_2010['date'].value_counts()\n",
    "\n",
    "print('2010: Mean', counts_2010.mean())\n",
    "\n",
    "accidents_2013 = pd.read_csv('input/ACCIDENTS_GU_BCN_2013.csv', encoding = 'latin-1')\n",
    "accidents_2013 = accidents_2013.rename(columns = parse_col_names(accidents_2013.columns))\n",
    "\n",
    "# create a new column which is the date\n",
    "accidents_2013['date'] = accidents_2013['dia_de_mes'].apply(lambda x: str(x)) + \\\n",
    "                         '-' + accidents_2013['mes_de_any'].apply(lambda x: str(x))\n",
    "\n",
    "dates_2013 = accidents_2013['date']\n",
    "counts_2013 = accidents_2013['date'].value_counts()\n",
    "\n",
    "print('2013: Mean', counts_2013.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This estimate suggests that in 2013 the mean rate of traffic accidents in Barcelona\n",
    "was higher than it was in 2010. But is this effect statistically significant?\n",
    "\n",
    "Based on our sample, the 95% confidence interval for the mean rate of traffic\n",
    "accidents in Barcelona during 2013 can be calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 accident rate estimate:  24.81095890410959\n",
      "2013 accident rate estimate:  25.90958904109589\n",
      "CI for 2013:  [24.975156065800284, 26.8440220163915]\n"
     ]
    }
   ],
   "source": [
    "n = len(counts_2013)\n",
    "mean = counts_2013.mean()\n",
    "s = counts_2013.std()\n",
    "ci = [mean - s * 1.96 / np.sqrt(n), mean + s * 1.96 / np.sqrt(n)]\n",
    "\n",
    "print('2010 accident rate estimate: ', counts_2010.mean())\n",
    "print('2013 accident rate estimate: ', counts_2013.mean())\n",
    "print('CI for 2013: ', ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the 2010 accident rate estimate does not fall in the range of plausible\n",
    "values of 2013, we say the alternative hypothesis cannot be discarded. That is, it\n",
    "cannot be ruled out that in 2013 the mean rate of traffic accidents in Barcelona was\n",
    "higher than in 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprteting CI Tests\n",
    "Hypothesis testing is built around rejecting or failing to reject the null hypothesis.\n",
    "That is, we do not reject $H_0$ unless we have strong evidence against it. But what\n",
    "precisely does strong evidence mean? As a general rule of thumb, for those cases\n",
    "where the null hypothesis is actually true, we do not want to incorrectly reject H 0\n",
    "more than 5% of the time. This corresponds to a significance level of $\\alpha =  0.05$. In\n",
    "this case, the correct interpretation of our test is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use a 95% confidence interval to test a problem where the null hypothesis is true, we\n",
    "will make an error whenever the point estimate is at least 1.96 standard errors away from the\n",
    "population parameter. This happens about 5% of the time (2.5% in each tail)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Testing Hypothesis Using _p_-values__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more advanced notion of statistical significance was developed by R.A. Fisher in\n",
    "the 1920s when he was looking for a test to decide whether variation in crop yields\n",
    "was due to some specific intervention or merely random factors beyond experimental\n",
    "control.\n",
    "\n",
    "Fisher first assumed that fertilizer caused no difference (_null hypothesis_) and then\n",
    "calculated $P$, the probability that an observed yield in a fertilized field would occur\n",
    "if fertilizer had no real effect. This probability is called the _p-value_.\n",
    "\n",
    "The _p-value_ is the probability of observing data at least as favorable to the alter-\n",
    "native hypothesis as our current dataset, if the null hypothesis is true. We typically\n",
    "use a summary statistic of the data to help compute the p-value and evaluate the\n",
    "hypotheses.\n",
    "\n",
    "Usually, if $P$ is less than 0.05 (the chance of a fluke is less than 5%) the result is\n",
    "declared __statistically significant__.\n",
    "It must be pointed out that this choice is rather arbitrary and should not be taken\n",
    "as a scientific truth.\n",
    "\n",
    "The goal of classical hypothesis testing is to answer the question, _“Given a sample\n",
    "and an apparent effect, what is the probability of seeing such an effect by chance?”_\n",
    "Here is how we answer that question:\n",
    " + The first step is to quantidy the size of the apparent effect by choosing\n",
    "   a test statistic. In our case, the apparent effect is a difference in \n",
    "   accident rates, so a natural choice for the test statistic is the __diferemce\n",
    "   in means between the two periods__.\n",
    " + The second step si to deifne a _null hypothesis_, which is a model of the system\n",
    "   based on the assumption that the apparent effect is not real. In our case,\n",
    "   the null hypothesis is that there is no difference between the two periods.\n",
    " + The third step is to compute a _p-value_, which is the probability of seeing\n",
    "   the apparent effect if the null hypothesis is true. In our case, we would\n",
    "   compute the difference in means, then compute the probability of seeing a \n",
    "   difference as big, or bigger, under the null hypothesis.\n",
    " + The last step is to _interpret the result. If the _p_-value is low, the effect\n",
    "   is said to be _statistically significant_, which means that it is unlikely to \n",
    "   have occurred by chance. In this case we infer that the effect is more likely\n",
    "   to appear in the larger population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:  365 n:  365\n",
      "mean difference:  1.0986301369863014\n"
     ]
    }
   ],
   "source": [
    "# computing test statistic\n",
    "m = len(counts_2010)\n",
    "n = len(counts_2013)\n",
    "p = (counts_2013.mean() - counts_2010.mean())\n",
    "\n",
    "print('m: ', m, 'n: ', n)\n",
    "print('mean difference: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value simulation:  0.0457 (4.57%)\n",
      "Difference: 1.0986301369863014\n"
     ]
    }
   ],
   "source": [
    "# approx the p-value\n",
    "# pooling distributions\n",
    "X = counts_2010\n",
    "Y = counts_2013\n",
    "\n",
    "pool = np.concatenate([X, Y])\n",
    "np.random.shuffle(pool)\n",
    "\n",
    "# sample generation\n",
    "import random\n",
    "N = 10000; diff = [0] * N\n",
    "for i in range(N):\n",
    "    p1 = [random.choice(pool) for __ in range(n)]\n",
    "    p2 = [random.choice(pool) for __ in range(n)]\n",
    "    diff[i] = (np.mean(p1) - np.mean(p2))\n",
    "\n",
    "# counting differences larger than the observed one\n",
    "diff2 = np.array(diff)\n",
    "w1 = np.where(diff2 > p)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value simulation:  0.0457 (4.57%)\n",
      "Difference: 1.099\n",
      "The effect is likely\n"
     ]
    }
   ],
   "source": [
    "print('p-value simulation: ', len(w1) / float(N), end = ' ')\n",
    "print(f'({len ( w1 ) / float ( N ) *100:.2f}%)')\n",
    "print(f'Difference: {p:.3f}')\n",
    "\n",
    "if (len(w1) / float(N)) < 0.05:\n",
    "    print('The effect is likely')\n",
    "else:\n",
    "    print('The effect is not likely')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting P-Values\n",
    "A _p_-value is the probability of an observed (or more extreme) result arising only\n",
    "from chance.\n",
    "If P is less than 0.05, there are two possible conclusions: there is a real effect or\n",
    "the result is an improbable fluke. __Fisher’s method offers no way of knowing which is\n",
    "the case.__\n",
    "\n",
    "We must not confuse the odds of getting a result (if a hypothesis is true) with\n",
    "the odds of favoritng the hypothesis if you observe that result. If $P$ is less than 0.05,\n",
    "we cannot say that this means that it is 95% certain that the observed effect is real\n",
    "and could not have arisen by chance. Given an observation $E$ and a hypothesis $H$,\n",
    "$P(E|H)$ and $P(H|E)$ are not the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common error equates _statistical significance to practical importance/relevance_.\n",
    "When working with large datasets, we can detect statistical significance\n",
    "for small effects that are meaningless in practical terms.\n",
    "\n",
    "We have defined the effect as a _difference in mean as large or larger than $\\delta$,\n",
    "considering the sign_. A test like this is called _one sided_.\n",
    "\n",
    "If the relevant question is whether _accident rates are different_, then it makes sense\n",
    "to test the absolute difference in means. This kind of test is called two sided because\n",
    "it counts both sides of the distribution of differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Approach\n",
    "The formula for the standard error of the absolute difference in two means\n",
    "is similar to the formula for other standard errors. Recall that the standard error\n",
    "of a single mean can be approximated by:\n",
    "    \n",
    "$$ SE_{\\bar{x}_1} = \\frac{\\sigma_1}{\\sqrt{n_1}} $$\n",
    "\n",
    "The standard error of the difference of two sample means can be constructed from the standard\n",
    "erros of the separate means:\n",
    "\n",
    "$$ SE_{\\bar{x}_1 - \\bar{x}_2} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}} $$\n",
    "\n",
    "This would allow us to define a direct test with the 95% confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the Effect $E$ Real?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not yet have an answer for this question! We have defined a null hypothesis\n",
    "$H_0$ (the effect is not real) and we have computed the probability of the observed\n",
    "effect under the null hypothesis, which is $P(E|H_0)$, where $E$ is an effect as big as\n",
    "or bigger than the apparent effect and a p-value .\n",
    "We have stated that from the frequentist point of view, we cannot consider H A\n",
    "unless $P(E|H_0)$ is less than an arbitrary value. But the real answer to this question\n",
    "must be based on comparing $P(H_0|E)$ to $P(H_A|E)$, not on $P(E|H_0)$! One possi-\n",
    "ble solution to these problems is to use __Bayesian reasoning__; an alternative to the\n",
    "frequentist approach.\n",
    "No matter how many data you have, you will still depend on intuition to decide\n",
    "how to interpret, explain, and use that data. Data cannot speak by themselves. Data\n",
    "scientists are interpreters, offering one interpretation of what the useful narrative\n",
    "story derived from the data is, if there is one at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('lab': virtualenv)",
   "language": "python",
   "name": "python37464bitlabvirtualenved77d976613b4753a84284c005b6ce98"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
